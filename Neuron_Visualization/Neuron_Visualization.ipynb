{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neuron_Visualization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShimonMalnick/ComputerVision/blob/master/Neuron_Visualization/Neuron_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OddXoV1SWczM",
        "colab_type": "text"
      },
      "source": [
        "# Network Architecture\n",
        "I use a pretrained [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), with architecture as shown below (credits to Krizhevsky et al.):\n",
        "\n",
        "![AlexNet Architecture](src/images/alexnet_architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAWUb-NhDx6D",
        "colab_type": "text"
      },
      "source": [
        "# Construct The AlexNet Classifier\n",
        "Note that like in the [Simonyan et al. 2014](https://arxiv.org/abs/1312.6034) paper, I've removed the softmax activation layer after the last fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chHEokoqMCm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, \\\n",
        "    unicode_literals\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation, \\\n",
        "    MaxPooling2D, Dropout\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class AlexNet(Model):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        # OPS\n",
        "        self.relu = Activation('relu')\n",
        "        self.maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2),\n",
        "                                    padding='valid')\n",
        "        # self.dropout = Dropout(0.4)  # droput can is discarded for inference\n",
        "\n",
        "        # Conv layers\n",
        "        self.conv1 = Conv2D(filters=96, input_shape=(224, 224, 3),\n",
        "                            kernel_size=(11, 11), strides=(4, 4),\n",
        "                            padding='same')\n",
        "        self.conv2a = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1),\n",
        "                             padding='same')\n",
        "        self.conv2b = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1),\n",
        "                             padding='same')\n",
        "        self.conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1),\n",
        "                            padding='same')\n",
        "        self.conv4a = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1),\n",
        "                             padding='same')\n",
        "        self.conv4b = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1),\n",
        "                             padding='same')\n",
        "        self.conv5a = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1),\n",
        "                             padding='same')\n",
        "        self.conv5b = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1),\n",
        "                             padding='same')\n",
        "\n",
        "        # Fully-connected layers\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "\n",
        "        self.dense1 = Dense(4096, input_shape=(100,))\n",
        "        self.dense2 = Dense(4096)\n",
        "        self.dense3 = Dense(1000)\n",
        "\n",
        "        # Network definition\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = tf.nn.local_response_normalization(x, depth_radius=2, alpha=2e-05,\n",
        "                                               beta=0.75, bias=1.0)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = tf.concat(\n",
        "            (self.conv2a(x[:, :, :, :48]), self.conv2b(x[:, :, :, 48:])), 3)\n",
        "        x = self.relu(x)\n",
        "        x = tf.nn.local_response_normalization(x, depth_radius=2, alpha=2e-05,\n",
        "                                               beta=0.75, bias=1.0)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = tf.concat(\n",
        "            (self.conv4a(x[:, :, :, :192]), self.conv4b(x[:, :, :, 192:])), 3)\n",
        "        x = self.relu(x)\n",
        "        x = tf.concat(\n",
        "            (self.conv5a(x[:, :, :, :192]), self.conv5b(x[:, :, :, 192:])), 3)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.dense1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dense3(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lusQxIEnImr",
        "colab_type": "text"
      },
      "source": [
        "# Define The Training Process\n",
        "Remember that instead of training the network and change its weights, we apply the gradients on the input image itself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Xvfa9xq3nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "89c4d849-b048-4e98-fbed-7aeb62967a74"
      },
      "source": [
        "REGULARIZITAION_LAMBDA = np.float(0.05)\n",
        "\n",
        "@tf.function\n",
        "def train_steps(model, I, neuron_idx):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictionsI = model(I)\n",
        "        score = predictionsI[0][neuron_idx]\n",
        "        regularizer = tf.math.reduce_mean(tf.math.square(I)) * REGULARIZITAION_LAMBDA\n",
        "        lossI = -(score - regularizer)\n",
        "    gradientsI = tape.gradient(lossI, I)\n",
        "    return gradientsI, lossI, score\n",
        "\n",
        "optimizerI = tf.keras.optimizers.Adam()\n",
        "\n",
        "def visualize_class(I, model, neuron_idx, number_of_iterations):\n",
        "\n",
        "    for i in range(number_of_iterations):\n",
        "        gradientI, lossI, score = train_steps(model, I, neuron_idx)\n",
        "        optimizerI.apply_gradients([(gradientI, I)])\n",
        "        cur_score = model(I)[0][neuron_idx]\n",
        "\n",
        "    return I.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "tf.Tensor(0.015955525, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.9552753, shape=(), dtype=float32)\n",
            "tf.Tensor(-0.97168684, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27nguXuAnRaE",
        "colab_type": "text"
      },
      "source": [
        "# Download The AlexNet Weights\n",
        "the weights can be found [here](https://drive.google.com/drive/folders/1E2CIRBfo3rYTSDJOaNOVkLgfBpTjF9cB?usp=sharing), and should be placed in src/alexnet_weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-MEzfmpnSpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "assert os.path.isdir('./src/alexnet_weights'), \"Please download the alexnet weights from the link above\"    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAAUEAh8nV8-",
        "colab_type": "text"
      },
      "source": [
        "# Load The Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpQr7wbnZJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = tf.Variable(tf.random.uniform((1, 224, 224, 3)))\n",
        "model = AlexNet()\n",
        "model(I)\n",
        "\n",
        "weights_dir = './src/alexnet_weights/'\n",
        "\n",
        "model.conv1.set_weights(\n",
        "    (np.load(weights_dir + 'conv1.npy'), np.load(weights_dir + 'conv1b.npy')))\n",
        "model.conv2a.set_weights(\n",
        "    (np.load(weights_dir + 'conv2_a.npy'), np.load(weights_dir + 'conv2b_a.npy')))\n",
        "model.conv2b.set_weights(\n",
        "    (np.load(weights_dir + 'conv2_b.npy'), np.load(weights_dir + 'conv2b_b.npy')))\n",
        "model.conv3.set_weights(\n",
        "    (np.load(weights_dir + 'conv3.npy'), np.load(weights_dir + 'conv3b.npy')))\n",
        "model.conv4a.set_weights(\n",
        "    (np.load(weights_dir + 'conv4_a.npy'), np.load(weights_dir + 'conv4b_a.npy')))\n",
        "model.conv5a.set_weights(\n",
        "    (np.load(weights_dir + 'conv5_a.npy'), np.load(weights_dir + 'conv5b_a.npy')))\n",
        "model.conv4b.set_weights(\n",
        "    (np.load(weights_dir + 'conv4_b.npy'), np.load(weights_dir + 'conv4b_b.npy')))\n",
        "model.conv5b.set_weights(\n",
        "    (np.load(weights_dir + 'conv5_b.npy'), np.load(weights_dir + 'conv5b_b.npy')))\n",
        "\n",
        "model.dense1.set_weights(\n",
        "    (np.load(weights_dir + 'dense1.npy'), np.load(weights_dir + 'dense1b.npy')))\n",
        "model.dense2.set_weights(\n",
        "    (np.load(weights_dir + 'dense2.npy'), np.load(weights_dir + 'dense2b.npy')))\n",
        "model.dense3.set_weights(\n",
        "    (np.load(weights_dir + 'dense3.npy'), np.load(weights_dir + 'dense3b.npy')))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR4dMfDunbSq",
        "colab_type": "text"
      },
      "source": [
        "# Optimize The Input Image\n",
        "Here the neuron I try to activate corresponds to the score of the class of 'parachute'.\n",
        "Classes ID's can be found in the classes.py file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22wlTOe3ndxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PARACHUTE_CLASS_ID = 701\n",
        "ITER_NUM = 20000\n",
        "\n",
        "im = visualize_class(I, model, PARACHUTE_CLASS_ID, ITER_NUM)\n",
        "\n",
        "#Normalizing the image for better results\n",
        "def normalize_im(I):\n",
        "  min = np.min(I, axis=(0, 1))\n",
        "  max = np.max(I, axis=(0, 1))\n",
        "  I = (I - min) / (max - min)\n",
        "  return I\n",
        "\n",
        "im = normalize_im(im[0])\n",
        "im = np.clip(np.flip(im, 2), 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnDguoX4nfq3",
        "colab_type": "text"
      },
      "source": [
        "# Show The Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-BNf-knngXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}